{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND0xI08OJfzXpP/TaOyaX7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dih08/projetos-simples-e-aleatorios/blob/main/Gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlF3113CWzLW",
        "outputId": "96cb41c9-5552-4f34-c51a-70140be219aa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "brEoiW7oVHut"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU, Activation\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imputando imagens\n",
        "\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "\n",
        "img_shape = (img_rows, img_cols, channels)\n"
      ],
      "metadata": {
        "id": "ELs6pbQ1Xa_w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    noise_shape = (100,)\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=noise_shape)\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dvSVHgmeX5xA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Flatten(input_shape=img_shape))\n",
        "  model.add(Dense(512))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dense(256))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.summary()\n",
        "\n",
        "  img = Input(shape=img_shape)\n",
        "  validity = model(img)\n",
        "\n",
        "  return Model(img, validity)\n"
      ],
      "metadata": {
        "id": "wmdUMTprY-IY"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming these functions are defined elsewhere\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "\n",
        "def save_imgs(epoch):\n",
        "  r, c = 5, 5\n",
        "  noise = np.random.normal(0, 1, (r * c, 100))\n",
        "  gen_imgs = generator.predict(noise)\n",
        "\n",
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "    # Load the MNIST dataset\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Normalize the dataset\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    intervalo_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, X_train.shape[0], intervalo_batch)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        # Generate fake images\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((intervalo_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs[:intervalo_batch], np.zeros((intervalo_batch, 1)))\n",
        "\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train the generator\n",
        "        z = Input(shape=(100,))\n",
        "        img = generator(z)\n",
        "        discriminator.trainable = False\n",
        "        valid = discriminator(img)\n",
        "        combined = Model(z, valid)\n",
        "        combined.compile(loss='binary_crossentropy', optimizer=Adam())\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
        "        valid_y = np.array([1] * batch_size)\n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "        print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)\n",
        "\n",
        "# Call the train function to start training\n",
        "epochs = 10\n",
        "train(epochs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWxyoHND3d3m",
        "outputId": "64927a8b-fc63-4687-9c00-496784d6c0b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 1024)              4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1493520 (5.70 MB)\n",
            "Trainable params: 1489936 (5.68 MB)\n",
            "Non-trainable params: 3584 (14.00 KB)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533505 (2.04 MB)\n",
            "Trainable params: 533505 (2.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "4/4 [==============================] - 0s 13ms/step\n",
            "0 [D loss: 0.877790, acc.: 14.84%] [G loss: 0.510630]\n",
            "1/1 [==============================] - 0s 446ms/step\n",
            "4/4 [==============================] - 0s 13ms/step\n",
            "1 [D loss: 0.356111, acc.: 73.44%] [G loss: 0.454590]\n",
            "4/4 [==============================] - 0s 16ms/step\n",
            "2 [D loss: 0.415670, acc.: 68.75%] [G loss: 0.528084]\n",
            "4/4 [==============================] - 0s 11ms/step\n",
            "3 [D loss: 0.522835, acc.: 57.81%] [G loss: 0.686397]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "4 [D loss: 0.491113, acc.: 64.06%] [G loss: 0.862128]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "5 [D loss: 0.397618, acc.: 73.44%] [G loss: 1.386154]\n",
            "4/4 [==============================] - 0s 12ms/step\n",
            "6 [D loss: 0.287644, acc.: 86.72%] [G loss: 2.100502]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "7 [D loss: 0.151515, acc.: 93.75%] [G loss: 2.555842]\n",
            "4/4 [==============================] - 0s 9ms/step\n",
            "8 [D loss: 0.064868, acc.: 98.44%] [G loss: 3.296327]\n",
            "4/4 [==============================] - 0s 7ms/step\n",
            "9 [D loss: 0.024117, acc.: 100.00%] [G loss: 3.826754]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(epoch):\n",
        "  r, c = 5, 5\n",
        "  noise = np.random.normal(0, 1, (r * c, 100))\n",
        "  gen_imgs = generator.predict(noise)\n",
        "\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(5, 5)\n",
        "  cnt = 0\n",
        "  for i in range(5):\n",
        "      for j in range(5):\n",
        "          axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "          axs[i,j].axis('off')\n",
        "          cnt += 1\n",
        "  # Create the 'images' directory if it doesn't exist\n",
        "  import os\n",
        "  if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "  fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "t_RyOe8w9Ngw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.0002, 0.5)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jrbwy2M-lfG3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkGKGjEFltgg",
        "outputId": "88091246-668f-4276-8525-d2e3c32b7778"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape_3 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1493520 (5.70 MB)\n",
            "Trainable params: 1489936 (5.68 MB)\n",
            "Non-trainable params: 3584 (14.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = Input(shape=(100,))\n",
        "img = generator(z)"
      ],
      "metadata": {
        "id": "3y81Sth4lxIF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.trainable = False"
      ],
      "metadata": {
        "id": "oPNUsMiHmH8f"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid = discriminator(img)"
      ],
      "metadata": {
        "id": "AwgmHWUDmK9I"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "vpJ9Li0gmNVB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(epochs=100, batch_size=32, save_interval=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHpwmVo6mVoD",
        "outputId": "a3d2dd37-1c75-4c9c-d110-7474ceb0e639"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 133ms/step\n",
            "0 [D loss: 0.049782, acc.: 100.00%] [G loss: 6.769795]\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1 [D loss: 0.056913, acc.: 100.00%] [G loss: 6.167862]\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "2 [D loss: 0.060905, acc.: 100.00%] [G loss: 5.806220]\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "3 [D loss: 0.062373, acc.: 100.00%] [G loss: 5.758904]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4 [D loss: 0.061767, acc.: 100.00%] [G loss: 5.335097]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5 [D loss: 0.062284, acc.: 100.00%] [G loss: 5.020932]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "6 [D loss: 0.071349, acc.: 100.00%] [G loss: 4.765901]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "7 [D loss: 0.076617, acc.: 100.00%] [G loss: 4.494195]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "8 [D loss: 0.102510, acc.: 93.75%] [G loss: 4.500502]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9 [D loss: 0.109397, acc.: 100.00%] [G loss: 4.110168]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "10 [D loss: 0.070576, acc.: 96.88%] [G loss: 3.934992]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "11 [D loss: 0.099905, acc.: 96.88%] [G loss: 3.643108]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "12 [D loss: 0.106908, acc.: 96.88%] [G loss: 3.443158]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "13 [D loss: 0.111005, acc.: 96.88%] [G loss: 3.298675]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "14 [D loss: 0.114938, acc.: 93.75%] [G loss: 2.935132]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "15 [D loss: 0.147680, acc.: 90.62%] [G loss: 2.954876]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "16 [D loss: 0.193503, acc.: 87.50%] [G loss: 2.615225]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "17 [D loss: 0.199858, acc.: 90.62%] [G loss: 2.460008]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "18 [D loss: 0.343839, acc.: 81.25%] [G loss: 2.667083]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "19 [D loss: 0.215713, acc.: 90.62%] [G loss: 2.640290]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "20 [D loss: 0.292844, acc.: 81.25%] [G loss: 2.352264]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "21 [D loss: 0.416063, acc.: 81.25%] [G loss: 2.257681]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "22 [D loss: 0.360129, acc.: 84.38%] [G loss: 1.845363]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "23 [D loss: 0.436353, acc.: 81.25%] [G loss: 2.166487]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "24 [D loss: 0.714057, acc.: 75.00%] [G loss: 1.886651]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "25 [D loss: 0.529413, acc.: 71.88%] [G loss: 2.376243]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "26 [D loss: 0.690832, acc.: 81.25%] [G loss: 1.888738]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "27 [D loss: 0.428357, acc.: 81.25%] [G loss: 2.540488]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "28 [D loss: 0.747568, acc.: 71.88%] [G loss: 1.743944]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "29 [D loss: 0.464015, acc.: 84.38%] [G loss: 1.627084]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "30 [D loss: 0.664648, acc.: 75.00%] [G loss: 1.570643]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "31 [D loss: 1.056505, acc.: 65.62%] [G loss: 1.168265]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "32 [D loss: 0.914871, acc.: 68.75%] [G loss: 1.412711]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "33 [D loss: 0.733143, acc.: 75.00%] [G loss: 1.534673]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "34 [D loss: 0.938625, acc.: 75.00%] [G loss: 1.845027]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "35 [D loss: 0.652465, acc.: 84.38%] [G loss: 1.458343]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "36 [D loss: 0.893703, acc.: 71.88%] [G loss: 1.611161]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "37 [D loss: 0.684248, acc.: 78.12%] [G loss: 1.185270]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "38 [D loss: 1.131395, acc.: 71.88%] [G loss: 1.465690]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "39 [D loss: 1.053677, acc.: 71.88%] [G loss: 1.312539]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "40 [D loss: 0.946125, acc.: 68.75%] [G loss: 1.396736]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "41 [D loss: 1.038235, acc.: 68.75%] [G loss: 1.524884]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "42 [D loss: 0.835831, acc.: 75.00%] [G loss: 1.362031]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "43 [D loss: 0.809413, acc.: 75.00%] [G loss: 1.162337]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "44 [D loss: 1.554513, acc.: 56.25%] [G loss: 0.831278]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "45 [D loss: 1.043754, acc.: 75.00%] [G loss: 1.187601]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "46 [D loss: 1.636696, acc.: 62.50%] [G loss: 1.305261]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "47 [D loss: 1.552423, acc.: 65.62%] [G loss: 0.960636]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "48 [D loss: 1.615234, acc.: 65.62%] [G loss: 1.193626]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "49 [D loss: 0.448209, acc.: 84.38%] [G loss: 1.705501]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "50 [D loss: 1.266028, acc.: 68.75%] [G loss: 0.673944]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "51 [D loss: 1.204575, acc.: 71.88%] [G loss: 0.955509]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "52 [D loss: 1.699767, acc.: 65.62%] [G loss: 1.436330]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "53 [D loss: 1.537023, acc.: 59.38%] [G loss: 0.655937]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "54 [D loss: 2.423169, acc.: 53.12%] [G loss: 1.017518]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "55 [D loss: 1.702156, acc.: 65.62%] [G loss: 0.726923]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "56 [D loss: 1.199053, acc.: 71.88%] [G loss: 0.610922]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "57 [D loss: 1.256601, acc.: 71.88%] [G loss: 1.101249]\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "58 [D loss: 0.951219, acc.: 78.12%] [G loss: 0.935882]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "59 [D loss: 1.295834, acc.: 65.62%] [G loss: 0.423537]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "60 [D loss: 1.761398, acc.: 71.88%] [G loss: 1.241831]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "61 [D loss: 2.282065, acc.: 56.25%] [G loss: 0.844880]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "62 [D loss: 1.401745, acc.: 71.88%] [G loss: 0.902766]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "63 [D loss: 1.636565, acc.: 59.38%] [G loss: 0.429042]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "64 [D loss: 1.202270, acc.: 62.50%] [G loss: 0.671173]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "65 [D loss: 1.880451, acc.: 59.38%] [G loss: 0.572325]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "66 [D loss: 1.152418, acc.: 71.88%] [G loss: 0.393925]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "67 [D loss: 2.185324, acc.: 53.12%] [G loss: 0.560866]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "68 [D loss: 2.621858, acc.: 53.12%] [G loss: 0.657089]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "69 [D loss: 1.820250, acc.: 62.50%] [G loss: 0.674080]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "70 [D loss: 2.332074, acc.: 59.38%] [G loss: 0.597311]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "71 [D loss: 1.868181, acc.: 56.25%] [G loss: 0.699881]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "72 [D loss: 2.764593, acc.: 62.50%] [G loss: 0.559081]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "73 [D loss: 2.135921, acc.: 56.25%] [G loss: 1.481268]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "74 [D loss: 2.172715, acc.: 62.50%] [G loss: 0.668214]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "75 [D loss: 1.461718, acc.: 71.88%] [G loss: 0.367921]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "76 [D loss: 2.488105, acc.: 62.50%] [G loss: 0.788061]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "77 [D loss: 2.296865, acc.: 68.75%] [G loss: 1.049103]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "78 [D loss: 1.779148, acc.: 65.62%] [G loss: 0.580478]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "79 [D loss: 2.810415, acc.: 62.50%] [G loss: 0.514875]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "80 [D loss: 2.734684, acc.: 62.50%] [G loss: 0.925978]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "81 [D loss: 2.486278, acc.: 59.38%] [G loss: 0.296262]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "82 [D loss: 2.173551, acc.: 71.88%] [G loss: 1.105127]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "83 [D loss: 2.134943, acc.: 59.38%] [G loss: 1.113679]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "84 [D loss: 1.276200, acc.: 75.00%] [G loss: 0.800037]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "85 [D loss: 2.204577, acc.: 62.50%] [G loss: 0.277222]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "86 [D loss: 2.436016, acc.: 62.50%] [G loss: 0.709156]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "87 [D loss: 2.786121, acc.: 59.38%] [G loss: 0.329624]\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "88 [D loss: 2.971192, acc.: 56.25%] [G loss: 0.930767]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "89 [D loss: 2.394022, acc.: 62.50%] [G loss: 0.863474]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "90 [D loss: 4.486012, acc.: 53.12%] [G loss: 0.675849]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "91 [D loss: 3.314969, acc.: 56.25%] [G loss: 0.566764]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "92 [D loss: 2.202246, acc.: 65.62%] [G loss: 0.665704]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "93 [D loss: 2.967247, acc.: 62.50%] [G loss: 1.226365]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "94 [D loss: 1.979137, acc.: 68.75%] [G loss: 0.824369]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "95 [D loss: 2.431402, acc.: 65.62%] [G loss: 0.431957]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "96 [D loss: 3.818943, acc.: 53.12%] [G loss: 0.823006]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "97 [D loss: 3.490090, acc.: 53.12%] [G loss: 0.471633]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "98 [D loss: 2.507325, acc.: 59.38%] [G loss: 1.318324]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "99 [D loss: 2.327898, acc.: 68.75%] [G loss: 1.356174]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save('generator.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2I7yDhzmyTH",
        "outputId": "a5f1f303-39cd-4bf2-cc1a-0a3b05c3600f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}